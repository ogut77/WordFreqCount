# -*- coding: utf-8 -*-
"""WordCountFrequency.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XGa09lAdVmmI7YkuVXj-Tah9wK0ki0JV
"""

#Setting up Apache Spark
!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q http://ftp.itu.edu.tr/Mirror/Apache/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz
!tar xf spark-2.4.0-bin-hadoop2.7.tgz
!pip install -q findspark

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-2.4.0-bin-hadoop2.7"

import findspark
findspark.init()
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").getOrCreate()

from pyspark import SparkContext
sc = SparkContext.getOrCreate()

from google.colab import drive

# This will prompt for authorization.
drive.mount('/content/drive')

import os

import urllib.request
shkspr=urllib.request.urlretrieve('https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt','/content/drive/My Drive/shakespeare.txt')

!ls '/content/drive/My Drive'

Words=sc.textFile("/content/drive/My Drive/shakespeare.txt")

WordsCount=Words.flatMap(lambda line: line.split(" ")).map(lambda word: (word, 1))
WordsCount.count()

DistinctWordsCount=WordsCount.reduceByKey(lambda a,b: a+b)
DistinctWordsCount.count()

SortedWordsCount=DistinctWordsCount.map(lambda a: (a[1], a[0])).sortByKey()
#print most frequent 20 words
SortedWordsCount.top(20)

#number of words=1418390-(517065, '')=901325
Sorted_final=SortedWordsCount.map(lambda a: (a[1], a[0]))
Sorted_final.top(20)